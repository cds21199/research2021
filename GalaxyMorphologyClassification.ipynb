{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GalaxyMorphologyClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FDEikBThYgHO",
        "bazPjDdWb82A",
        "hKW7aZFX5rv9",
        "rpcaKWWy6o7T",
        "SffXxy3NsiHS",
        "Wmm3vp5b82JG",
        "x2a-3ftdMY9a",
        "4Pw6XFltEr0g",
        "jQwO73SmxIjT"
      ],
      "mount_file_id": "1ElvyX7sstQxcBq_26RAZxgfWu3GjdnAM",
      "authorship_tag": "ABX9TyOOvI5zu7LqR9WelxRaj5hN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cds21199/research2021/blob/main/GalaxyMorphologyClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYzusFu0qiLl"
      },
      "source": [
        "# Galaxy Morphology Classification - ChloÃ« Smith\n",
        "## University of the Witwatersrand\n",
        "## Supervisor - Dr. Ritesh Ajoodha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDEikBThYgHO"
      },
      "source": [
        "## Setup and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3qEygTcnaZm"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-J9xdpVntON"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32MoOR3O-uwF"
      },
      "source": [
        "#!pip install imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhuuPT_lNIPn"
      },
      "source": [
        "#!pip3 install keras-visualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suwjR22qC-eO"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcHQhQWlc2hV"
      },
      "source": [
        "cd drive/My Drive/Research Project/galaxy-zoo-kaggle/training/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-at7X6JYdnP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, Input\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I95WWAK7S2P"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bazPjDdWb82A"
      },
      "source": [
        "# Load dataframe containing image filenames and probabilities for each question (our targets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjn7cP7-6zDh"
      },
      "source": [
        "# load training labels\n",
        "df_dist = pd.read_csv(\"solutions/training_solutions_rev1.csv\")\n",
        "df_dist.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgfO9DWo7X50"
      },
      "source": [
        "classes = ['Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2', 'Class3.1',\n",
        "           'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1', 'Class5.2', 'Class5.3',\n",
        "           'Class5.4', 'Class6.1', 'Class6.2', 'Class7.1', 'Class7.2', 'Class7.3',\n",
        "           'Class8.1', 'Class8.2', 'Class8.3', 'Class8.4', 'Class8.5', 'Class8.6',\n",
        "           'Class8.7', 'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1', 'Class10.2',\n",
        "           'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3', 'Class11.4', 'Class11.5', 'Class11.6']\n",
        "#df_dist['Max'] = df_dist[classes].idxmax(axis=1)\n",
        "#df_dist[['GalaxyID', 'Max']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqPQR36XwYQx"
      },
      "source": [
        "### Convert IDs to filenames (i.e. add extension .jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFtjdjVRweJx"
      },
      "source": [
        "df_dist['GalaxyID'] = df_dist['GalaxyID'].astype(str).apply(lambda x: str(x) + \".jpg\")\n",
        "df_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKW7aZFX5rv9"
      },
      "source": [
        "# Load images and resize, no augmentation yet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwudWVzPWA3_"
      },
      "source": [
        "def preprocessing(img):\n",
        "  out = img\n",
        "  # TODO\n",
        "\n",
        "  assert np.shape(out) == np.shape(img)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWa4fokJNbYv"
      },
      "source": [
        "# ImageDataGenerator does our preprocessing\n",
        "datagen = ImageDataGenerator()\n",
        "# some resizing is done here, to 224x224 images\n",
        "train_generator = datagen.flow_from_dataframe(dataframe=train, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)\n",
        "valid_generator = datagen.flow_from_dataframe(dataframe=test, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpcaKWWy6o7T"
      },
      "source": [
        "# Benchmark transfer learning model (ResNet)\n",
        "\n",
        "We are exploring the effects of different feature sets, this model uses no handcrafted feature extraction.\n",
        "\n",
        "We train ResNet-50 on the images that have only been scaled down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FBqwgQNbBa3"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FotZveOd1dCI"
      },
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# add a fully-connected layer to train for our specific dataset\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "# add a prediction layer (softmax) for our 37 target features\n",
        "predictions = Dense(37, activation='softmax')(x)\n",
        "\n",
        "# train only top layers\n",
        "# freeze the hidden layers from ResNet50\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# model to train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# compile model, done after freezing layers\n",
        "model.compile(optimizer='Adam', loss='mse', metrics=[\"mae\", \"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzACF1pXM1R7"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx2Fae7HNQ1_"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "#plot_model(model, to_file=\"../model-11-17.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fD3OuPO5ZfR"
      },
      "source": [
        "# train the modecl\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "with tf.device('/gpu:0'):\n",
        "  model.fit(train_generator,\n",
        "            steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "            validation_data=valid_generator,\n",
        "            validation_steps=STEP_SIZE_VALID,\n",
        "            epochs=3)\n",
        "\n",
        "# save the model\n",
        "model.save('../ResNet50/11-17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SffXxy3NsiHS"
      },
      "source": [
        "## load saved model and run for more epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTH0vSCyVCQI"
      },
      "source": [
        "# load the model\n",
        "#new_model = keras.models.load_model('../custom/11-07')\n",
        "#np.testing.assert_allclose(model.predict(train_generator),\n",
        "                #new_model.predict(train_generator),\n",
        "                #1e-5)\n",
        "#new_model.evaluate(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2SqMdMMVp8X"
      },
      "source": [
        "# fit the model\n",
        "#checkpoint = keras.callbacks.ModelCheckpoint('../checkpoints/11-31', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "#callbacks_list = [checkpoint]\n",
        "#STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "#STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "#history = new_model.fit(train_generator,\n",
        "            steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "            validation_data=valid_generator,\n",
        "            validation_steps=STEP_SIZE_VALID,\n",
        "            epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz0Jae3sVsFK"
      },
      "source": [
        "# save new model\n",
        "#new_model.save('../ResNet50/11-31')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptiznZOZ64yR"
      },
      "source": [
        "# New model (benchmark?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvCwOhSb9IM1"
      },
      "source": [
        "model = Sequential()\n",
        "# input 224 x 224 x 3\n",
        "model.add(Conv2D(224, (3, 3), padding='same',\n",
        "                 input_shape=(224,224,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# added for VGG-16\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "# end\n",
        "\n",
        "model.add(Flatten())\n",
        "#model1.add(Dense(2048)) # changed from 512 to 4096 to 2048\n",
        "#model1.add(Activation('relu'))\n",
        "model.add(Dense(1024)) # added for VGG-16, halved all nodes\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512)) # added, reduced for a bottleneck\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(37, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9OePXPTHpnE"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmm3vp5b82JG"
      },
      "source": [
        "### Model with no augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVEtNXGH81qm"
      },
      "source": [
        "# split train into train and dev sets\n",
        "train, test = train_test_split(df_dist, test_size=0.2, random_state=42, shuffle=True)\n",
        "#display(train)\n",
        "\n",
        "# load images from buffer, dataset is large\n",
        "# original images are 424 x 424 pixels\n",
        "datagen = ImageDataGenerator()\n",
        "# some resizing is done here, to 224x224 images\n",
        "train_generator = datagen.flow_from_dataframe(dataframe=train, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)\n",
        "valid_generator = datagen.flow_from_dataframe(dataframe=test, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft_HRl5Q9lc4"
      },
      "source": [
        "#plot_model(model, to_file=\"../model-11-18.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l2ar6sA9cZS"
      },
      "source": [
        "# train the model\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='mse', metrics=[\"acc\", tf.keras.metrics.RootMeanSquaredError()])\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "history = model.fit(train_generator,\n",
        "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "          validation_data=valid_generator,\n",
        "          validation_steps=STEP_SIZE_VALID,\n",
        "          epochs=50)\n",
        "\n",
        "# save the model\n",
        "model.save('../custom/11-19')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA4Kc_o7MTu8"
      },
      "source": [
        "### In-place data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSL1GSuCxJK6"
      },
      "source": [
        "# split train into train and dev sets\n",
        "train, test = train_test_split(df_dist, test_size=0.2, random_state=42, shuffle=True)\n",
        "#display(train)\n",
        "\n",
        "# load images from buffer, dataset is large\n",
        "# original images are 424 x 424 pixels\n",
        "datagen = ImageDataGenerator(width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             vertical_flip=True,\n",
        "                             rotation_range=45,\n",
        "                             fill_mode='nearest')\n",
        "# some resizing is done here, to 224x224 images\n",
        "train_generator = datagen.flow_from_dataframe(dataframe=train, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)\n",
        "valid_generator = datagen.flow_from_dataframe(dataframe=test, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bMYwllmYT_o"
      },
      "source": [
        "# train the model\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss=tf.keras.losses.MeanSquaredError(), metrics=[\"acc\", tf.keras.metrics.RootMeanSquaredError()])\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "history = model.fit(train_generator,\n",
        "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "          validation_data=valid_generator,\n",
        "          validation_steps=STEP_SIZE_VALID,\n",
        "          epochs=30)\n",
        "\n",
        "# save the model\n",
        "model.save('../custom/11-23')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhzAAVDNxnRj"
      },
      "source": [
        "dir(valid_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjEeOmf_wIcz"
      },
      "source": [
        "out = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC6RwTpxxj-0"
      },
      "source": [
        "m = tf.keras.metrics.CosineSimilarity(axis=1)\n",
        "acc = m.update_state(out, y_test)\n",
        "acc = m.result().numpy()\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2a-3ftdMY9a"
      },
      "source": [
        "### Model, loss functions and learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg5Z6Ljd_X4B"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10 or lr <= 0.000001:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StHEqXIV-VDp"
      },
      "source": [
        "def rmse(y_true, y_pred):\n",
        "  # root mean squared error\n",
        "  return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBl0jPQ6_S5W"
      },
      "source": [
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaWmrx18694L"
      },
      "source": [
        "model1 = Sequential()\n",
        "# input 224 x 224 x 3\n",
        "model1.add(Conv2D(224, (3, 3), padding='same',\n",
        "                 input_shape=(224,224,3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(64, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(128, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "# added for VGG-16\n",
        "model1.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(256, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(256, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(256, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Conv2D(256, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "# end\n",
        "\n",
        "model1.add(Flatten())\n",
        "#model1.add(Dense(2048)) # changed from 512 to 4096 to 2048\n",
        "#model1.add(Activation('relu'))\n",
        "model1.add(Dense(1024)) # added for VGG-16, halved all nodes\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dense(512)) # added, reduced for a bottleneck\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(37, activation='softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "model1.compile(optimizer=opt, loss=rmse, metrics=[\"acc\"])\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "history = model1.fit(train_generator,\n",
        "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "          validation_data=valid_generator,\n",
        "          validation_steps=STEP_SIZE_VALID,\n",
        "          epochs=50,\n",
        "          callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-4MhKk7hqb"
      },
      "source": [
        "# save new model\n",
        "model1.save('../aug/11-17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pw6XFltEr0g"
      },
      "source": [
        "## Feature extraction and data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz9i6YejFTvT"
      },
      "source": [
        "def augment_set(data, seq):\n",
        "  aug = []\n",
        "  for image in data:\n",
        "    seq_det = seq.to_deterministic()\n",
        "    img = seq_det.augment_image(image)\n",
        "  return aug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB0kslV7FKeI"
      },
      "source": [
        "# TODO augment training set\n",
        "seq = iaa.Sequential([\n",
        "      iaa.Fliplr(0.5), # horizontal flips\n",
        "      iaa.Crop(percent=(0, 0.1)), # random crops\n",
        "      iaa.LinearContrast((0.75, 1.5)),\n",
        "      #iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "      #iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
        "      iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        mode='edge'\n",
        "    )\n",
        "])\n",
        "\n",
        "aug = []\n",
        "for image in train:\n",
        "  seq_det = seq.to_deterministic()\n",
        "  img = seq_det.augment_image(image.image)\n",
        "  mask = seq_det.augment_image(image.mask)\n",
        "  mask[mask < 0.5] = 0\n",
        "  mask[mask >= 0.5] = 1\n",
        "  aug.append(LabelledImage(image.num, preprocess(img), preprocess(mask)))\n",
        "\n",
        "print(len(aug))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhS3erj3EvXY"
      },
      "source": [
        "# split train into train and dev sets\n",
        "train, test = train_test_split(df_dist, test_size=0.2, random_state=42, shuffle=True)\n",
        "#display(train)\n",
        "\n",
        "# load images from buffer, dataset is large\n",
        "# original images are 424 x 424 pixels\n",
        "datagen = ImageDataGenerator(width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             vertical_flip=True,\n",
        "                             rotation_range=45,\n",
        "                             fill_mode='nearest')\n",
        "# some resizing is done here, to 45x45 images\n",
        "train_generator = datagen.flow_from_dataframe(dataframe=train, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)\n",
        "valid_generator = datagen.flow_from_dataframe(dataframe=test, \n",
        "                                      directory=\"images/images_training_rev1\", \n",
        "                                      x_col=\"GalaxyID\", \n",
        "                                      y_col=classes, \n",
        "                                      class_mode=\"raw\", \n",
        "                                      target_size=(224,224), \n",
        "                                      batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQwO73SmxIjT"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGvsEs_2yEmh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO2oPuCzqKQJ"
      },
      "source": [
        "## code blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCGnbzw4LfBx"
      },
      "source": [
        "model = Sequential()\n",
        "# input 224 x 224 x 3\n",
        "model.add(Conv2D(224, (3, 3), padding='same',\n",
        "                 input_shape=(224,224,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# added for VGG-16\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "# end\n",
        "\n",
        "model.add(Flatten())\n",
        "#model1.add(Dense(2048)) # changed from 512 to 4096 to 2048\n",
        "#model1.add(Activation('relu'))\n",
        "model.add(Dense(1024)) # added for VGG-16, halved all nodes\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512)) # added, reduced for a bottleneck\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(37, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV0TzoEgL-JK"
      },
      "source": [
        "#plot_model(model, to_file=\"../model-11-17.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIforfnQ1H8b"
      },
      "source": [
        "#!pip3 install keras-visualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_8yAr91Ikm"
      },
      "source": [
        "from keras_visualizer import visualizer\n",
        "visualizer(model, format='png', view=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSh47UzQ1QoY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}